{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Auto_ML_Classification_Churn: H20_AutoKeras_MLBOX",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNh9ugXxRtATdFZwDwxnX3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcury/Machine-Learning-Projects/blob/main/Auto_ML_Classification_Churn_H20_AutoKeras_MLBOX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lib H20"
      ],
      "metadata": {
        "id": "kU_1SQPm1H6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install h2o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blDePJTZs_Qs",
        "outputId": "bb185700-54a5-458a-abae-b0ea82149c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h2o in /usr/local/lib/python3.7/dist-packages (3.36.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from h2o) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from h2o) (0.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from h2o) (0.8.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRffoKb4fnF9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "f6570ee2-b11f-4772-c945-7f1fbfe2d77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.15\" 2022-04-19; OpenJDK Runtime Environment (build 11.0.15+10-Ubuntu-0ubuntu0.18.04.1); OpenJDK 64-Bit Server VM (build 11.0.15+10-Ubuntu-0ubuntu0.18.04.1, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.7/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmpjn7cimt8\n",
            "  JVM stdout: /tmp/tmpjn7cimt8/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmpjn7cimt8/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  ----------------------------------\n",
              "H2O_cluster_uptime:         05 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.36.1.3\n",
              "H2O_cluster_version_age:    20 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_2g68bl\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.172 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.7.13 final\n",
              "--------------------------  ----------------------------------"
            ],
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>05 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.36.1.3</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>20 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_2g68bl</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.172 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.7.13 final</td></tr></table></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ],
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "import pandas as pd\n",
        "\n",
        "h2o.init()\n",
        "\n",
        "#Importa dados e divide em treino e teste\n",
        "imp = pd.read_csv('Churn_treino.csv', sep=\";\")\n",
        "imp = h2o.H2OFrame(imp)\n",
        "treino,teste = imp.split_frame(ratios=[.7])\n",
        "\n",
        "#Transforma a variável dependente em fator\n",
        "treino[\"Exited\"] = treino[\"Exited\"].asfactor()\n",
        "teste[\"Exited\"] = teste[\"Exited\"].asfactor()\n",
        "\n",
        "#Busca o modelo por 60 segundos, podemos em vez disso definir max_models\n",
        "modelo = H2OAutoML(max_runtime_secs=60)\n",
        "modelo.train( y=\"Exited\", training_frame=treino)\n",
        "\n",
        "#Ranking dos melhores\n",
        "ranking = modelo.leaderboard\n",
        "ranking = ranking.as_data_frame()\n",
        "\n",
        "#Prever \n",
        "teste = pd.read_csv('Churn_prever.csv', sep=\";\")\n",
        "teste = h2o.H2OFrame(teste)\n",
        "prever = modelo.leader.predict(teste)\n",
        "prever = prever.as_data_frame(prever)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "SVYIVyFqtqMs",
        "outputId": "b37f5e3b-1baa-4925-a5e8-ce1ad739dabd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   predict        p0        p1\n",
              "0        0  0.927846  0.072154\n",
              "1        0  0.938973  0.061027\n",
              "2        1  0.033352  0.966648\n",
              "3        0  0.976565  0.023435\n",
              "4        0  0.922064  0.077936\n",
              "5        0  0.920497  0.079503\n",
              "6        0  0.748518  0.251482\n",
              "7        0  0.941067  0.058933\n",
              "8        0  0.874548  0.125452"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b96c77ec-5d43-44d5-8133-ee6d36fd1ee8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predict</th>\n",
              "      <th>p0</th>\n",
              "      <th>p1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.927846</td>\n",
              "      <td>0.072154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.938973</td>\n",
              "      <td>0.061027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.033352</td>\n",
              "      <td>0.966648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.976565</td>\n",
              "      <td>0.023435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.922064</td>\n",
              "      <td>0.077936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0.920497</td>\n",
              "      <td>0.079503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0.748518</td>\n",
              "      <td>0.251482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0.941067</td>\n",
              "      <td>0.058933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0.874548</td>\n",
              "      <td>0.125452</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b96c77ec-5d43-44d5-8133-ee6d36fd1ee8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b96c77ec-5d43-44d5-8133-ee6d36fd1ee8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b96c77ec-5d43-44d5-8133-ee6d36fd1ee8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lib AutoKeras"
      ],
      "metadata": {
        "id": "XMe_40wZ1PY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autokeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vm3vvsNWuIML",
        "outputId": "db3221bc-9e89-4eb1-be44-731093b50906"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: autokeras in /usr/local/lib/python3.7/dist-packages (1.0.19)\n",
            "Collecting tensorflow>=2.8.0\n",
            "  Using cached tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (21.3)\n",
            "Requirement already satisfied: keras-tuner>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.1.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (0.25.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.23.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (5.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.18.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.0.2)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.12)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.26.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.47.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (14.0.1)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Collecting tensorboard\n",
            "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (4.1.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.8.0->autokeras) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n",
            "Installing collected packages: numpy, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.18.2\n",
            "    Uninstalling numpy-1.18.2:\n",
            "      Successfully uninstalled numpy-1.18.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.0.1\n",
            "    Uninstalling tensorflow-estimator-2.0.1:\n",
            "      Successfully uninstalled tensorflow-estimator-2.0.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.0.2\n",
            "    Uninstalling tensorboard-2.0.2:\n",
            "      Successfully uninstalled tensorboard-2.0.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.0.0\n",
            "    Uninstalling tensorflow-2.0.0:\n",
            "      Successfully uninstalled tensorflow-2.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 0.25.3 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.4.1 which is incompatible.\n",
            "prophet 1.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.3 which is incompatible.\n",
            "mlbox 0.8.5 requires numpy==1.18.2, but you have numpy 1.21.6 which is incompatible.\n",
            "mlbox 0.8.5 requires tensorflow==2.0.0, but you have tensorflow 2.9.1 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.3 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.14 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.6 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imp.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "n9cDK-zr2G_l",
        "outputId": "5db6d20b-2e25-42a6-efd3-c94e46dee8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th style=\"text-align: right;\">  CreditScore</th><th>Geography  </th><th>Gender  </th><th style=\"text-align: right;\">  Age</th><th style=\"text-align: right;\">  Tenure</th><th style=\"text-align: right;\">    Balance</th><th style=\"text-align: right;\">  NumOfProducts</th><th style=\"text-align: right;\">  HasCrCard</th><th style=\"text-align: right;\">  IsActiveMember</th><th style=\"text-align: right;\">  EstimatedSalary</th><th style=\"text-align: right;\">  Exited</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td style=\"text-align: right;\">          619</td><td>France     </td><td>Female  </td><td style=\"text-align: right;\">   42</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">0          </td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">      1.01349e+07</td><td style=\"text-align: right;\">       1</td></tr>\n",
              "<tr><td style=\"text-align: right;\">          608</td><td>Spain      </td><td>Female  </td><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">8.38079e+06</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">      1.12543e+07</td><td style=\"text-align: right;\">       0</td></tr>\n",
              "<tr><td style=\"text-align: right;\">          502</td><td>France     </td><td>Female  </td><td style=\"text-align: right;\">   42</td><td style=\"text-align: right;\">       8</td><td style=\"text-align: right;\">1.59661e+06</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">      1.13932e+07</td><td style=\"text-align: right;\">       1</td></tr>\n",
              "<tr><td style=\"text-align: right;\">          699</td><td>France     </td><td>Female  </td><td style=\"text-align: right;\">   39</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">0          </td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">      9.38266e+06</td><td style=\"text-align: right;\">       0</td></tr>\n",
              "<tr><td style=\"text-align: right;\">          850</td><td>Spain      </td><td>Female  </td><td style=\"text-align: right;\">   43</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">1.25511e+07</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\"> 790841          </td><td style=\"text-align: right;\">       0</td></tr>\n",
              "<tr><td style=\"text-align: right;\">          645</td><td>Spain      </td><td>Male    </td><td style=\"text-align: right;\">   44</td><td style=\"text-align: right;\">       8</td><td style=\"text-align: right;\">1.13756e+07</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">      1.49757e+07</td><td style=\"text-align: right;\">       1</td></tr>\n",
              "<tr><td style=\"text-align: right;\">          822</td><td>France     </td><td>Male    </td><td style=\"text-align: right;\">   50</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0          </td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\"> 100628          </td><td style=\"text-align: right;\">       0</td></tr>\n",
              "<tr><td style=\"text-align: right;\">          376</td><td>Germany    </td><td>Female  </td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">1.15047e+07</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">      1.19347e+07</td><td style=\"text-align: right;\">       1</td></tr>\n",
              "<tr><td style=\"text-align: right;\">          501</td><td>France     </td><td>Male    </td><td style=\"text-align: right;\">   44</td><td style=\"text-align: right;\">       4</td><td style=\"text-align: right;\">1.42051e+07</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\"> 749405          </td><td style=\"text-align: right;\">       0</td></tr>\n",
              "<tr><td style=\"text-align: right;\">          684</td><td>France     </td><td>Male    </td><td style=\"text-align: right;\">   27</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">1.34604e+07</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">      7.17257e+06</td><td style=\"text-align: right;\">       0</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import autokeras as ak\n",
        "import pandas as pd\n",
        "\n",
        "#Importa dados\n",
        "imp = pd.read_csv('Churn_treino.csv', sep=\";\")\n",
        "\n",
        "#Separa variaveis independentes da classe\n",
        "x = imp.iloc[:,0:10]\n",
        "y = imp.iloc[:,10]\n",
        "\n",
        "# Inicializa com 10 modelos diferentes\n",
        "modelo = ak.StructuredDataClassifier(max_trials=10) \n",
        "\n",
        "#Cria o modelo\n",
        "modelo.fit( x= x, y =y, epochs=100)\n",
        "\n",
        "#Previsão\n",
        "prever = pd.read_csv('Churn_prever.csv', sep=\";\")\n",
        "previsao = modelo.predict(prever)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWx981Svtq7s",
        "outputId": "d34c3879-a164-4045-daa0-740d1996a35c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./structured_data_classifier/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from ./structured_data_classifier/tuner0.json\n",
            "WARNING:tensorflow:AutoGraph could not transform <function split_dataset.<locals>.<lambda> at 0x7fc22e97f7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function split_dataset.<locals>.<lambda> at 0x7fc22e97f7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function HyperPipeline.build.<locals>.<lambda> at 0x7fc22c231d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function HyperPipeline.build.<locals>.<lambda> at 0x7fc22c231d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function HyperPipeline.build.<locals>.<lambda> at 0x7fc22c1cbb90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function HyperPipeline.build.<locals>.<lambda> at 0x7fc22c1cbb90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cbc20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cbc20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cba70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cba70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function AddOneDimension.__init__.<locals>.<lambda> at 0x7fc22c1c68c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function AddOneDimension.__init__.<locals>.<lambda> at 0x7fc22c1c68c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Pipeline.fit.<locals>.<lambda> at 0x7fc22c231d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Pipeline.fit.<locals>.<lambda> at 0x7fc22c231d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cbdd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cbdd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Pipeline.fit.<locals>.<lambda> at 0x7fc22c1cbb90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Pipeline.fit.<locals>.<lambda> at 0x7fc22c1cbb90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cbc20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cbc20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc22c231d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc22c231d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc22c1cbc20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc22c1cbc20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cb950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cb950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cbb90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c1cbb90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc22c0815f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc22c0815f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc22c0f27a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc22c0f27a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c081320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c081320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c0f2b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c0f2b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method MultiCategoryEncoding.call of <autokeras.keras_layers.MultiCategoryEncoding object at 0x7fc22c15ded0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method MultiCategoryEncoding.call of <autokeras.keras_layers.MultiCategoryEncoding object at 0x7fc22c15ded0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "WARNING:tensorflow:AutoGraph could not transform <function HyperPipeline.build.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function HyperPipeline.build.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function HyperPipeline.build.<locals>.<lambda> at 0x7fc235ca60e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function HyperPipeline.build.<locals>.<lambda> at 0x7fc235ca60e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22eaea440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22eaea440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c081cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22c081cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Pipeline.fit.<locals>.<lambda> at 0x7fc235ca60e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Pipeline.fit.<locals>.<lambda> at 0x7fc235ca60e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22bf47680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22bf47680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Pipeline.fit.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Pipeline.fit.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22eaea440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22eaea440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc22eaea440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc22eaea440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Pipeline.transform.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22bf47680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22bf47680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22bfa1ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc22bfa1ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function AutoTuner.adapt.<locals>.<lambda> at 0x7fc22bf475f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function AutoTuner.adapt.<locals>.<lambda> at 0x7fc22bf475f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function AutoTuner.adapt.<locals>.<lambda> at 0x7fc22c231d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function AutoTuner.adapt.<locals>.<lambda> at 0x7fc22c231d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22eb0d050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22eb0d050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function cast_to_string at 0x7fc22c4ce710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function cast_to_string at 0x7fc22c4ce710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22bf473b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22bf473b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22eb08440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22eb08440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22bf47440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22bf47440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22bf56050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22bf56050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22bf56200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22bf56200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22be6eef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22be6eef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22c078320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22c078320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22bea1440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22bea1440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22c078200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22c078200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22be328c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22be328c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22be32ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22be32ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22be2fdd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22be2fdd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22be2f170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22be2f170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22be2f950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function MultiCategoryEncoding.adapt.<locals>.<lambda> at 0x7fc22be2f950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22bdf7a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22bdf7a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22e97f7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc22e97f7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc22bdc08c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc22bdc08c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 0.4986 - accuracy: 0.7850\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4582 - accuracy: 0.8076\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4343 - accuracy: 0.8171\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4083 - accuracy: 0.8327\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3953 - accuracy: 0.8376\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3910 - accuracy: 0.8372\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3899 - accuracy: 0.8386\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3863 - accuracy: 0.8422\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3831 - accuracy: 0.8435\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3810 - accuracy: 0.8453\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3801 - accuracy: 0.8416\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3796 - accuracy: 0.8448\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3773 - accuracy: 0.8436\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8459\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8457\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3738 - accuracy: 0.8466\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3717 - accuracy: 0.8466\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3731 - accuracy: 0.8459\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3697 - accuracy: 0.8465\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3705 - accuracy: 0.8481\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3703 - accuracy: 0.8456\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3715 - accuracy: 0.8469\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3701 - accuracy: 0.8476\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3679 - accuracy: 0.8454\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3676 - accuracy: 0.8463\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3659 - accuracy: 0.8490\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3660 - accuracy: 0.8482\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3676 - accuracy: 0.8481\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3662 - accuracy: 0.8473\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3655 - accuracy: 0.8492\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3644 - accuracy: 0.8506\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8472\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3632 - accuracy: 0.8493\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3618 - accuracy: 0.8509\n",
            "Epoch 35/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3624 - accuracy: 0.8509\n",
            "Epoch 36/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3601 - accuracy: 0.8511\n",
            "Epoch 37/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3611 - accuracy: 0.8506\n",
            "Epoch 38/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3588 - accuracy: 0.8505\n",
            "Epoch 39/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3611 - accuracy: 0.8492\n",
            "Epoch 40/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3592 - accuracy: 0.8513\n",
            "Epoch 41/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3586 - accuracy: 0.8522\n",
            "Epoch 42/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3595 - accuracy: 0.8506\n",
            "Epoch 43/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3590 - accuracy: 0.8496\n",
            "Epoch 44/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.8491\n",
            "Epoch 45/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3574 - accuracy: 0.8522\n",
            "Epoch 46/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3571 - accuracy: 0.8488\n",
            "Epoch 47/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3561 - accuracy: 0.8521\n",
            "Epoch 48/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3561 - accuracy: 0.8532\n",
            "Epoch 49/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3534 - accuracy: 0.8510\n",
            "Epoch 50/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3556 - accuracy: 0.8514\n",
            "Epoch 51/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.8520\n",
            "Epoch 52/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3556 - accuracy: 0.8528\n",
            "Epoch 53/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3540 - accuracy: 0.8539\n",
            "Epoch 54/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3530 - accuracy: 0.8533\n",
            "Epoch 55/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3569 - accuracy: 0.8498\n",
            "Epoch 56/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3541 - accuracy: 0.8527\n",
            "Epoch 57/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3555 - accuracy: 0.8514\n",
            "Epoch 58/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3550 - accuracy: 0.8499\n",
            "Epoch 59/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3536 - accuracy: 0.8524\n",
            "Epoch 60/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3516 - accuracy: 0.8518\n",
            "Epoch 61/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3532 - accuracy: 0.8540\n",
            "Epoch 62/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3511 - accuracy: 0.8539\n",
            "Epoch 63/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3504 - accuracy: 0.8536\n",
            "Epoch 64/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3516 - accuracy: 0.8522\n",
            "Epoch 65/100\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.3513 - accuracy: 0.8521\n",
            "Epoch 66/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3520 - accuracy: 0.8546\n",
            "Epoch 67/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3505 - accuracy: 0.8543\n",
            "Epoch 68/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3469 - accuracy: 0.8554\n",
            "Epoch 69/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8539\n",
            "Epoch 70/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8522\n",
            "Epoch 71/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3497 - accuracy: 0.8551\n",
            "Epoch 72/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3508 - accuracy: 0.8530\n",
            "Epoch 73/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3496 - accuracy: 0.8544\n",
            "Epoch 74/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3497 - accuracy: 0.8538\n",
            "Epoch 75/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3486 - accuracy: 0.8549\n",
            "Epoch 76/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3504 - accuracy: 0.8539\n",
            "Epoch 77/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3483 - accuracy: 0.8564\n",
            "Epoch 78/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3490 - accuracy: 0.8556\n",
            "Epoch 79/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3501 - accuracy: 0.8554\n",
            "Epoch 80/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3497 - accuracy: 0.8534\n",
            "Epoch 81/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8552\n",
            "Epoch 82/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3479 - accuracy: 0.8569\n",
            "Epoch 83/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8547\n",
            "Epoch 84/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3470 - accuracy: 0.8570\n",
            "Epoch 85/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3474 - accuracy: 0.8551\n",
            "Epoch 86/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3481 - accuracy: 0.8529\n",
            "Epoch 87/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.8597\n",
            "Epoch 88/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3460 - accuracy: 0.8558\n",
            "Epoch 89/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8563\n",
            "Epoch 90/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3474 - accuracy: 0.8551\n",
            "Epoch 91/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3466 - accuracy: 0.8572\n",
            "Epoch 92/100\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3463 - accuracy: 0.8560\n",
            "Epoch 93/100\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.3449 - accuracy: 0.8559\n",
            "Epoch 94/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8567\n",
            "Epoch 95/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3435 - accuracy: 0.8578\n",
            "Epoch 96/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3454 - accuracy: 0.8568\n",
            "Epoch 97/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3452 - accuracy: 0.8545\n",
            "Epoch 98/100\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3448 - accuracy: 0.8569\n",
            "Epoch 99/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3430 - accuracy: 0.8576\n",
            "Epoch 100/100\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3402 - accuracy: 0.8599\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fc22c231d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fc22c231d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fc22bd09a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fc22bd09a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276fe290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276fe290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc2277123b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc2277123b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2277124d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2277124d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc2276fe320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc2276fe320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276fe3b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276fe3b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc2276b0200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc2276b0200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276b0170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276b0170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc227712cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc227712cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276b0950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276b0950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc2276fe320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc2276fe320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276fe440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276fe440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc227662680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc227662680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276fe290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc2276fe290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc227662680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc227662680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc227662f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.save_fn at 0x7fc227662f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc227662320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function trace_save_restore_functions.<locals>.restore_fn at 0x7fc227662320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22773ce60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22773ce60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc227a02b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc227a02b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22c1c6c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22c1c6c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22ba57830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22ba57830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc227a02b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc227a02b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22e90ecb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22e90ecb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc235fbd4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22c1c6c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22c1c6c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22ba57830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22ba57830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc227a02b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc227a02b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22be2fef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22be2fef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc227a02b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc227a02b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22c1c6c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc22c1c6c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n",
            "WARNING:tensorflow:AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc227787680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function unzip_dataset.<locals>.<listcomp>.<lambda> at 0x7fc227787680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Constant'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc22772c7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc22772c7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "1/1 [==============================] - 0s 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lib mlbox"
      ],
      "metadata": {
        "id": "8NcKDMfA1T_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mlbox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n-JF1dGsxpkW",
        "outputId": "bae124bd-e429-430c-9a47-ab99fffe591d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlbox in /usr/local/lib/python3.7/dist-packages (0.8.5)\n",
            "Requirement already satisfied: scikit-learn==0.22.1 in /usr/local/lib/python3.7/dist-packages (from mlbox) (0.22.1)\n",
            "Requirement already satisfied: lightgbm==2.3.1 in /usr/local/lib/python3.7/dist-packages (from mlbox) (2.3.1)\n",
            "Requirement already satisfied: xlrd==1.2.0 in /usr/local/lib/python3.7/dist-packages (from mlbox) (1.2.0)\n",
            "Requirement already satisfied: matplotlib==3.0.3 in /usr/local/lib/python3.7/dist-packages (from mlbox) (3.0.3)\n",
            "Requirement already satisfied: tables==3.5.2 in /usr/local/lib/python3.7/dist-packages (from mlbox) (3.5.2)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/dist-packages (from mlbox) (0.25.3)\n",
            "Collecting numpy==1.18.2\n",
            "  Using cached numpy-1.18.2-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "Requirement already satisfied: joblib==0.14.1 in /usr/local/lib/python3.7/dist-packages (from mlbox) (0.14.1)\n",
            "Collecting tensorflow==2.0.0\n",
            "  Using cached tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3 MB)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from mlbox) (1.4.1)\n",
            "Requirement already satisfied: hyperopt==0.2.3 in /usr/local/lib/python3.7/dist-packages (from mlbox) (0.2.3)\n",
            "Requirement already satisfied: networkx==2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.3->mlbox) (2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.3->mlbox) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.3->mlbox) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.3->mlbox) (4.64.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.3->mlbox) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.3->mlbox) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.3->mlbox) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.3->mlbox) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.3->mlbox) (3.0.9)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx==2.2->hyperopt==0.2.3->mlbox) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->mlbox) (2022.1)\n",
            "Requirement already satisfied: mock>=2.0 in /usr/local/lib/python3.7/dist-packages (from tables==3.5.2->mlbox) (4.0.3)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables==3.5.2->mlbox) (2.8.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (0.8.1)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "  Using cached tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.14.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (0.37.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.0.8)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "  Using cached tensorboard-2.0.2-py3-none-any.whl (3.8 MB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.47.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0->mlbox) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.0.3->mlbox) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr>=2.6.2->tables==3.5.2->mlbox) (21.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (3.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (3.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.0.0->mlbox) (1.5.2)\n",
            "Installing collected packages: numpy, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.1\n",
            "    Uninstalling tensorflow-2.9.1:\n",
            "      Successfully uninstalled tensorflow-2.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 0.25.3 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.2 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.4.1 which is incompatible.\n",
            "prophet 1.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.3 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.3 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.2 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.2 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.14 requires numpy>=1.19, but you have numpy 1.18.2 which is incompatible.\n",
            "jax 0.3.14 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.18.2 which is incompatible.\n",
            "autokeras 1.0.19 requires tensorflow>=2.8.0, but you have tensorflow 2.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.18.2 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mlbox.preprocessing import *\n",
        "from mlbox.optimisation import *\n",
        "from mlbox.prediction import *\n",
        "\n",
        "#Caminho dos arquivos de treino e teste\n",
        "caminho = [\"Churn_treino.csv\",\"Churn_teste.csv\"]\n",
        "\n",
        "#prepara os dados, exclui colunas inuteis, define tipos, extrai informaçõeses importantes etc\n",
        "imp = Reader(sep = \";\")\n",
        "dados = imp.train_test_split(caminho, \"Exited\")\n",
        "\n",
        "#Drif\n",
        "rdrift = Drift_thresholder()\n",
        "dados = rdrift.fit_transform(dados)\n",
        "\n",
        "#Objeto otimizador\n",
        "otimizador = Optimiser()\n",
        "\n",
        "#Paramametros do otimizaodr, do tipo dicionário\n",
        "espaco = {\n",
        "     'fs__strategy':{\"search\":\"choice\",\"space\":[\"variance\",\"rf_feature_importance\"]},\n",
        "     'est__colsample_bytree':{\"search\":\"uniform\", \"space\":[0.3,0.7]}\n",
        "}\n",
        "\n",
        "#Criacao do modelo de fato\n",
        "# max_evals é as interação, default é 40\n",
        "modelo = otimizador.optimise(espaco,dados,max_evals=15)\n",
        "\n",
        "#previsão\n",
        "previsor = Predictor()\n",
        "previsor.fit_predict(modelo, dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_qYsWNH_vOpJ",
        "outputId": "a4e242c4-9c2b-473e-a055-7ae906e1fd64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "reading csv : Churn_treino.csv ...\n",
            "cleaning data ...\n",
            "CPU time: 8.696735382080078 seconds\n",
            "\n",
            "reading csv : Churn_teste.csv ...\n",
            "cleaning data ...\n",
            "CPU time: 0.20542478561401367 seconds\n",
            "\n",
            "> Number of common features : 10\n",
            "\n",
            "gathering and crunching for train and test datasets ...\n",
            "reindexing for train and test datasets ...\n",
            "dropping training duplicates ...\n",
            "dropping constant variables on training set ...\n",
            "\n",
            "> Number of categorical features: 2\n",
            "> Number of numerical features: 8\n",
            "> Number of training samples : 10000\n",
            "> Number of test samples : 2474\n",
            "\n",
            "> You have no missing values on train set...\n",
            "\n",
            "> Task : classification\n",
            "0.0    7963\n",
            "1.0    2037\n",
            "Name: Exited, dtype: int64\n",
            "\n",
            "encoding target ...\n",
            "\n",
            "computing drifts ...\n",
            "CPU time: 0.7295377254486084 seconds\n",
            "\n",
            "> Top 10 drifts\n",
            "\n",
            "('CreditScore', 0.039029506871463227)\n",
            "('Balance', 0.036350121261115476)\n",
            "('Age', 0.03163581244947444)\n",
            "('EstimatedSalary', 0.01662118027485837)\n",
            "('HasCrCard', 0.012770008084074469)\n",
            "('Gender', 0.0063882780921584725)\n",
            "('Tenure', 0.002330476960388239)\n",
            "('Geography', 0.002216248989490799)\n",
            "('IsActiveMember', 0.0017504446240903526)\n",
            "('NumOfProducts', 0.0011434114793855699)\n",
            "\n",
            "> Deleted variables : []\n",
            "> Drift coefficients dumped into directory : save\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.35613887027931646, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "  0%|          | 0/15 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/optimisation/optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory 'save/joblib'. Please clear it regularly.\n",
            "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : neg_log_loss = -0.3953278943317498\n",
            "VARIANCE : 0.0037817845316901466 (fold 1 = -0.39910967886343995, fold 2 = -0.39154610980005966)\n",
            "CPU time: 7.037454843521118 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.39358106341716226, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.3970314969740216\n",
            "VARIANCE : 0.000690560822930425 (fold 1 = -0.3977220577969521, fold 2 = -0.3963409361510912)\n",
            "CPU time: 6.702322483062744 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.3435460227674123, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.3953278943317498\n",
            "VARIANCE : 0.0037817845316901466 (fold 1 = -0.39910967886343995, fold 2 = -0.39154610980005966)\n",
            "CPU time: 4.565527439117432 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.4453946291438813, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.3970314969740216\n",
            "VARIANCE : 0.000690560822930425 (fold 1 = -0.3977220577969521, fold 2 = -0.3963409361510912)\n",
            "CPU time: 4.347567081451416 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.4758230448938675, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.39896546981969894\n",
            "VARIANCE : 0.002624533668607737 (fold 1 = -0.4015900034883067, fold 2 = -0.3963409361510912)\n",
            "CPU time: 8.8242506980896 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.3970540936991098, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.3970314969740216\n",
            "VARIANCE : 0.000690560822930425 (fold 1 = -0.3977220577969521, fold 2 = -0.3963409361510912)\n",
            "CPU time: 4.328802824020386 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.5130570751126367, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.40486925862169043\n",
            "VARIANCE : 0.001919342854489664 (fold 1 = -0.40678860147618007, fold 2 = -0.40294991576720074)\n",
            "CPU time: 4.145467281341553 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.6253117668354808, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.4044676216181195\n",
            "VARIANCE : 0.0015177058509187602 (fold 1 = -0.40598532746903826, fold 2 = -0.40294991576720074)\n",
            "CPU time: 5.720363140106201 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.4099235738591287, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.3970314969740216\n",
            "VARIANCE : 0.000690560822930425 (fold 1 = -0.3977220577969521, fold 2 = -0.3963409361510912)\n",
            "CPU time: 5.062256813049316 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.37384693135726377, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.39896546981969894\n",
            "VARIANCE : 0.002624533668607737 (fold 1 = -0.4015900034883067, fold 2 = -0.3963409361510912)\n",
            "CPU time: 1.571195125579834 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.5125583799096934, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.4044676216181195\n",
            "VARIANCE : 0.0015177058509187602 (fold 1 = -0.40598532746903826, fold 2 = -0.40294991576720074)\n",
            "CPU time: 1.5719923973083496 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.46986101616134635, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.39896546981969894\n",
            "VARIANCE : 0.002624533668607737 (fold 1 = -0.4015900034883067, fold 2 = -0.3963409361510912)\n",
            "CPU time: 1.6397788524627686 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.3330312175068386, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.39513400132068977\n",
            "VARIANCE : 0.0035878915206300765 (fold 1 = -0.3987218928413198, fold 2 = -0.39154610980005966)\n",
            "CPU time: 1.5979795455932617 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.5025177668994121, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.4044676216181195\n",
            "VARIANCE : 0.0015177058509187602 (fold 1 = -0.40598532746903826, fold 2 = -0.40294991576720074)\n",
            "CPU time: 4.58545994758606 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'colsample_bytree': 0.31619767909152735, 'boosting_type': 'gbdt', 'class_weight': None, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_log_loss = -0.3953278943317498\n",
            "VARIANCE : 0.0037817845316901466 (fold 1 = -0.39910967886343995, fold 2 = -0.39154610980005966)\n",
            "CPU time: 2.860640287399292 seconds\n",
            "100%|██████████| 15/15 [01:05<00:00,  4.35s/trial, best loss: 0.39513400132068977]\n",
            "\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "{'est__colsample_bytree': 0.3330312175068386, 'fs__strategy': 'rf_feature_importance'}\n",
            "\n",
            "fitting the pipeline ...\n",
            "CPU time: 3.6132700443267822 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Feature importances dumped into directory : save\n",
            "\n",
            "predicting ...\n",
            "CPU time: 0.15732693672180176 seconds\n",
            "\n",
            "> Overview on predictions : \n",
            "\n",
            "        0.0       1.0  Exited_predicted\n",
            "0  0.706120  0.293880                 0\n",
            "1  0.980511  0.019489                 0\n",
            "2  0.936784  0.063216                 0\n",
            "3  0.207324  0.792676                 1\n",
            "4  0.370915  0.629085                 1\n",
            "5  0.952282  0.047718                 0\n",
            "6  0.928365  0.071635                 0\n",
            "7  0.635891  0.364109                 0\n",
            "8  0.353668  0.646332                 1\n",
            "9  0.760367  0.239633                 0\n",
            "\n",
            "dumping predictions into directory : save ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mlbox.prediction.predictor.Predictor at 0x7fd44c42a9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}